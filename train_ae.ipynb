{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mschoene/clvr_impl_starter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd clvr_impl_starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install virtualenv\n",
    "!virtualenv -p $(which python3) ./venv\n",
    "!source ./venv/bin/activate\n",
    "# Install dependencies\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sprites_datagen.moving_sprites import MovingSpriteDataset,DistractorTemplateMovingSpritesGenerator\n",
    "\n",
    "from sprites_env.envs.sprites import SpritesEnv\n",
    "from sprites_datagen.rewards import *\n",
    "\n",
    "from general_utils import AttrDict\n",
    "from torch.utils.data import Dataset, DataLoader,IterableDataset\n",
    "from datasets import load_dataset\n",
    "from general_utils import * #make_image_seq_strip\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sprites_datagen.moving_sprites \n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchviz import make_dot\n",
    "import matplotlib as plt\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from models import ImageEncoder, ImageDecoder, AE, Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = AttrDict(\n",
    "        resolution=64,\n",
    "        max_seq_len=2, #30,\n",
    "        max_speed=0.05,      # total image range [0, 1]\n",
    "        obj_size=0.2,       # size of objects, full images is 1.0\n",
    "        shapes_per_traj=20,      # number of shapes per trajectory\n",
    "        rewards=[ZeroReward]\n",
    "    )\n",
    "\n",
    "n_conditioning_frames = 3\n",
    "n_prediction_frames = 6 #TODO change to 25 or w/e\n",
    "batch_size = 4096 #2048 #1024\n",
    "n_batches = 200\n",
    "n_samples = batch_size * n_batches\n",
    "\n",
    "test_ds = MovingSpriteDataset(spec=spec, num_samples=n_samples)\n",
    "\n",
    "dataloader = DataLoader(test_ds, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "input_channels = 3\n",
    "output_size = 64\n",
    "\n",
    "encoder = ImageEncoder(input_channels=3, output_size=64)\n",
    "decoder = ImageDecoder(input_channels=64, output_size=64)\n",
    "\n",
    "# Create an instance of Autoencoder\n",
    "autoencoder = AE(encoder, decoder)\n",
    "model = autoencoder\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.RAdam( model.parameters(), betas = (0.9, 0.999), weight_decay=0.001)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        inputs_pre = sample_batched.images[:, 0, ...].squeeze(1)\n",
    "        labels = sample_batched.images[:, 0, ...].squeeze(1)\n",
    "\n",
    "        inputs = inputs_pre.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #inputs.retain_grad = True\n",
    "        #inputs.requires_grad = True\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()     \n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i_batch % n_batches == 0:\n",
    "            last_loss = running_loss / float(batch_size) # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i_batch + 1, last_loss))\n",
    "            #print(' l1 loss ', l1_lambda * l1_loss )\n",
    "            tb_x = epoch_index * len(dataloader) + i_batch + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(dataloader): #validation_loader):\n",
    "            vinputs, vlabels = vdata.images[:, 0, ...].squeeze(1), vdata.images[:, 0, ...].squeeze(1)\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            #print(vinputs.shape, vlabels.shape)\n",
    "            voutputs = model(vinputs)\n",
    "            #print(voutputs.shape)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1.)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        #torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, vdata  in enumerate(dataloader):\n",
    "    #this is the way to adopt the same plotting for the dataset images as for the traj images\n",
    "    # it's a bit hacky but it works, so it's not stupid :,) also I don't need to change the code in multiple places so it's a win...\n",
    "    # undo this/ (255./2) - 1.0\n",
    "    print(vdata.images.shape )\n",
    "    vinputs, vlabels = vdata.images[:, 0, ...], vdata.images[:, 0, ...].squeeze(1)\n",
    "    print(vinputs.shape,vdata.images.shape )\n",
    "\n",
    "    vinputs = vinputs.to(device)\n",
    "\n",
    "    voutputs = model(vinputs)\n",
    "    vinputs = vinputs.to('cpu')\n",
    "\n",
    "    voutputs = voutputs.cpu().detach().numpy()\n",
    "    img = make_image_seq_strip([ ((1+vinputs[None, :])*(255/2.))] ,n_logged_samples=5,sep_val=255.0).astype(np.uint8)\n",
    "    cv2.imwrite(\"test_input.png\", img[0].transpose(1, 2, 0))\n",
    "    voutputs = voutputs[:5, ...] * 2 - 1\n",
    "    #print(voutputs)\n",
    "    print(vinputs.shape,vdata.images.shape )\n",
    "\n",
    "    img = make_image_seq_strip([ ((1+voutputs[None, :])*(255/2.))] ,n_logged_samples=5,sep_val=255.0).astype(np.uint8)\n",
    "    cv2.imwrite(\"test_output.png\", img[0].transpose(1, 2, 0))\n",
    "    if i ==0:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
